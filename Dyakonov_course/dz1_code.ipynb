{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GPshszNSFsmf"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.datasets.samples_generator import make_gaussian_quantiles\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial.distance import pdist\n",
    "import sklearn.datasets as skl\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bM1v2cSEHtq7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def init_ctrs_prob(points, k):\n",
    "    '''\n",
    "        Inint centers with the probability D^2(x)/sum(D^2(yi))\n",
    "\n",
    "        x - current point\n",
    "        yi - point from data\n",
    "    '''\n",
    "    centroids = np.zeros(shape=(1, 2)) \n",
    "    centroids[0] = points[np.random.randint( \n",
    "        points.shape[0]), :] \n",
    "    for c_id in range(1, k): \n",
    "        \n",
    "        dst = np.empty((1, points.shape[0]), dtype=float)\n",
    "        threshold = np.random.rand(1)\n",
    "        for ind in range(points.shape[0]):\n",
    "            dst[0][ind] = np.min(np.sum((centroids - points[ind, :]) ** 2, axis = 1))\n",
    "        dst = np.cumsum(dst)\n",
    "        if dst[-1] == 0:\n",
    "            break\n",
    "        dst /= dst[-1]\n",
    "        for ind in range(dst.shape[0]):\n",
    "            if dst[ind] > threshold:\n",
    "                centroids = np.vstack((centroids, points[ind]))\n",
    "                break \n",
    "    if (k - points.shape[0] > 0):\n",
    "            centroids = np.vstack((centroids, \n",
    "                                   points[np.random.randint(0, points.shape[0], \n",
    "                                    k - points.shape[0])]))\n",
    "    return centroids\n",
    "\n",
    "def init_ctrs_random(points, k):\n",
    "    return X[np.random.randint(points.shape[0], size=k)]\n",
    "\n",
    "def find_clusters(X, n_centers, init='probability'):\n",
    "    # 1. Choose the cluster based on random\n",
    "    if init == 'random':\n",
    "        centers = init_ctrs_random(X, n_centers)\n",
    "    elif init == 'probability':\n",
    "        centers = init_ctrs_prob(X, n_centers)\n",
    "    else:\n",
    "        return np.full(n_centers, np.nan), np.full(X.shape[0], np.nan)\n",
    "    \n",
    "    while True:\n",
    "        # 2a. Assign labels based on closest center\n",
    "        labels = np.argmin(cdist(centers, X, 'euclidean'), axis=0)\n",
    "        \n",
    "        # 2b. Find new centers from means of points\n",
    "        new_centers = np.array([[0, 0]])\n",
    "        for i in range(n_centers):\n",
    "          if (X[labels == i].size != 0):\n",
    "            new_centers = np.concatenate((new_centers, np.array([X[labels == i].mean(0)])))\n",
    "          else:\n",
    "            new_centers = np.concatenate((new_centers, np.array([centers[i]])))\n",
    "        new_centers = new_centers[1:]\n",
    "        # 2c. Check for convergence\n",
    "        if np.all(centers == new_centers):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    return centers, labels\n",
    "\n",
    "def tg(p1, p2):\n",
    "    if p1[0] == p2[0]:\n",
    "        if p1[1] < p2[1]:\n",
    "            return np.inf\n",
    "        elif p1[1] > p2[1]:\n",
    "            return -np.inf\n",
    "        else:\n",
    "            return 0\n",
    "    return (p2[1] - p1[1]) / (p2[0] - p1[0])\n",
    "\n",
    "def WSS(X, labels, centers):\n",
    "    return np.sum(np.array([np.sum((X[labels == i] - centers[i])**2) \n",
    "                                         for i in range(centers.shape[0])]))\n",
    "\n",
    "def elbow_method(X, eps=0.2, init='probability'):\n",
    "    wss = np.array([])\n",
    "    count_cl = 1\n",
    "    centers, labels = find_clusters(X, count_cl, init)\n",
    "    wss = np.append(wss, WSS(X, labels, centers))\n",
    "    count_cl += 1\n",
    "    while True:\n",
    "        centers, labels = find_clusters(X, count_cl, init)\n",
    "        wss = np.append(wss, WSS(X, labels, centers))\n",
    "        if (np.abs(tg(np.array([count_cl - 1, wss[count_cl - 2]]), \n",
    "                np.array([count_cl, wss[count_cl - 1]]))) < eps):\n",
    "            count_cl -= 1\n",
    "            break\n",
    "        count_cl += 1\n",
    "    #one more plot\n",
    "    centers, labels = find_clusters(X, count_cl + 1, init)\n",
    "    wss = np.append(wss, WSS(X, labels, centers))\n",
    "    return wss, count_cl\n",
    "    \n",
    "def point_silhouette(ind_p, X, labels):\n",
    "    if (np.sum(labels == labels[ind_p]) == 1):\n",
    "        return 0\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    mrang = np.delete(unique, np.argwhere(unique == labels[ind_p]))\n",
    "    a = np.sum(cdist(X[labels == labels[ind_p]], X[ind_p].reshape(1, 2), 'euclidean'), axis=0) / (counts[np.argwhere(unique == labels[ind_p])] - 1)\n",
    "    b = np.min(np.array([(np.sum(cdist(X[labels == ind_c], X[ind_p].reshape(1, 2), 'euclidean'), axis=0)) \n",
    "                        / counts[np.argwhere(unique == ind_c)]\n",
    "                         for ind_c in mrang]))\n",
    "    return (b - a)/np.max(np.append(a, b))\n",
    "    \n",
    "def average_silhouette_method(X, max_amount_cl=12,  init='probability'):\n",
    "    av_siluets = np.array([])\n",
    "    count_cl = 2\n",
    "    while count_cl != max_amount_cl:\n",
    "        siluets = 0.0\n",
    "        centers, labels = find_clusters(X, count_cl, init)\n",
    "        for ind_p in range(X.shape[0]):\n",
    "            siluets += point_silhouette(ind_p, X, labels)\n",
    "        av_siluets = np.append(av_siluets, siluets/X.shape[0])\n",
    "        count_cl += 1\n",
    "    return av_siluets\n",
    "        \n",
    "def print_k_methods(X, eps=0.2, max_amout_cl = 12):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(15, 8))\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.3)\n",
    "    \n",
    "    wss, count_cl = elbow_method(X, eps, init='random')\n",
    "    axs[0,0].title.set_text(\"Random init\")\n",
    "    axs[0,0].plot(range(1, wss.shape[0] + 1), wss, 'kx-')\n",
    "    axs[0,0].plot(count_cl, wss[count_cl - 1], 'og', label='Best count clasters')\n",
    "    axs[0,0].set(ylabel = 'WSS')\n",
    "\n",
    "    av_siluets = average_silhouette_method(X, max_amout_cl, init='random')  \n",
    "    axs[0,1].title.set_text(\"Random init\")\n",
    "    axs[0,1].plot(range(2, max_amout_cl), av_siluets, 'mx-')\n",
    "    axs[0,1].plot(np.argmax(av_siluets) + 2, np.max(av_siluets), 'sg', label='Best count clasters')\n",
    "    axs[0,1].set(ylabel = 'Avg silhouette')\n",
    "\n",
    "    wss, count_cl = elbow_method(X, eps, init='probability')\n",
    "    axs[1,0].title.set_text(\"Probabilistic init\")\n",
    "    axs[1,0].plot(range(1, wss.shape[0] + 1), wss, 'kx-')\n",
    "    axs[1,0].plot(count_cl, wss[count_cl - 1], 'og', label='Best count clasters')\n",
    "    axs[1,0].set(xlabel = 'Values of K', ylabel = 'WSS')\n",
    "\n",
    "    av_siluets = average_silhouette_method(X, max_amout_cl, init='probability') \n",
    "    axs[1,1].title.set_text(\"Probabilistic init\") \n",
    "    axs[1,1].plot(range(2, max_amout_cl), av_siluets, 'mx-')\n",
    "    axs[1,1].plot(np.argmax(av_siluets) + 2, np.max(av_siluets), 'sg', label='Best count clasters')\n",
    "    axs[1,1].set(xlabel = 'Values of K', ylabel = 'Avg silhouette')\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    plt.show()\n",
    "        \n",
    "def print_find_cl(X, n_centers=4):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    plt.subplots_adjust(wspace=0.4)\n",
    "\n",
    "    s_centers = init_ctrs_random(X, n_centers)\n",
    "    centers, labels = find_clusters(X, n_centers, init='random')\n",
    "    axs[0].scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis');\n",
    "    axs[0].scatter(s_centers[:,0], s_centers[:,1], c='violet', label='Start centers');\n",
    "    axs[0].title.set_text(\"Random init\")\n",
    "    axs[0].legend()\n",
    "    \n",
    "    s_centers = init_ctrs_prob(X, n_centers)\n",
    "    centers, labels = find_clusters(X, n_centers, init='probability')\n",
    "    axs[1].scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis');\n",
    "    axs[1].scatter(s_centers[:,0], s_centers[:,1], c='violet', label='Start centers');\n",
    "    axs[1].title.set_text(\"Probabilistic init\")\n",
    "    axs[1].legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def print_sdist_matrix(X, n_clusters, K=4):\n",
    "    '''\n",
    "        Print sorted distance matrix in two ways:\n",
    "            1) Sorted by cluster\n",
    "            2) Sorted by cluster and distance between the biggest cluster and others\n",
    "\n",
    "        X - generated data\n",
    "        n_clusters - initial count of clusters\n",
    "        K - desired count of clusters\n",
    "    '''\n",
    "    fig, axs = plt.subplots(1, 2, num=1, figsize=(14, 5))\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "    centers, labels = find_clusters(X, K)\n",
    "\n",
    "    #Sorted by labels\n",
    "    X3 = X[np.argsort(labels), :]\n",
    "    X3 = squareform(pdist(X3))\n",
    "    axs[1].title.set_text(\"Only sorted by cluster\") \n",
    "    axs[1].matshow(X3,cmap='Purples_r')\n",
    "    axs[1].set_xticks([])\n",
    "\n",
    "    #Sorted by labels and dist between biggest cluster and current\n",
    "    ind_l, count_in_l = np.unique(labels, return_counts=True)\n",
    "    ind_maxc = ind_l[np.argmax(count_in_l)]\n",
    "    permutation = (np.argsort(cdist(centers, [centers[ind_maxc]]), axis=0)).ravel()\n",
    "    s_labels = np.copy(labels)\n",
    "    for i in range(s_labels.shape[0]):\n",
    "        s_labels[i], = np.where(permutation == s_labels[i])\n",
    "    X3 = X[np.argsort(s_labels), :]\n",
    "    X3 = squareform(pdist(X3))\n",
    "\n",
    "    axs[0].title.set_text(\"Sorted by cluster and dist btw clrs\")\n",
    "    im = axs[0].matshow(X3,cmap='Purples_r')\n",
    "    axs[0].set_xticks([])\n",
    "    fig.colorbar(im, ax=axs.ravel().tolist(), orientation='vertical',pad=0.06);\n",
    "    fig.suptitle('K = ' + str(K) + '\\n n_clusters = ' + str(n_clusters), x=0.425, y=1 , fontsize=14)\n",
    "\n",
    "    plt.show() \n",
    "\n",
    "def predict_clusters():   # -> testing time ...\n",
    "    pass\n",
    "\n",
    "def best_clustwers(X):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "colab_type": "code",
    "id": "s1NHPHmkJRPW",
    "outputId": "26028083-886f-4785-cdb3-98f4b2afb44d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_samples = 400\n",
    "n_clusters = 5\n",
    "cluster_std = 0.6 + N_samples/500000\n",
    "random_state = 11\n",
    "X, y_true = make_blobs(n_samples=N_samples, centers=n_clusters,\n",
    "                       cluster_std=cluster_std, random_state=random_state)\n",
    "print_find_cl(X, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "sSsH5PTRsLhm",
    "outputId": "253b4c7e-5a23-4c74-b190-2a7b619033db"
   },
   "outputs": [],
   "source": [
    "X, y_true = skl.make_circles(n_samples=100, shuffle=True, noise=0.1, random_state=1, factor=0.1)\n",
    "print_find_cl(X, 2)\n",
    "X, y_true = skl.make_moons(n_samples=100, shuffle=True, noise=0.05, random_state=0)\n",
    "print_find_cl(X, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 852
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "DY65QrKCIdCP",
    "outputId": "25590b1b-f920-4466-970b-bd76ce2643e9"
   },
   "outputs": [],
   "source": [
    "N_samples = 600\n",
    "n_clusters = 5\n",
    "cluster_std = 0.5\n",
    "random_state = 9\n",
    "X, y_true = make_blobs(n_samples=N_samples, centers=n_clusters,\n",
    "                       cluster_std=cluster_std, random_state=random_state)\n",
    "print_find_cl(X, n_clusters)\n",
    "print_k_methods(X, eps=1000, max_amout_cl=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bAClJslOuUG0"
   },
   "outputs": [],
   "source": [
    "count_itp = 10\n",
    "count_itk = 10\n",
    "start_p = 1000\n",
    "start_k = 2\n",
    "inc_mul_p = 2\n",
    "inc_add_k = 1\n",
    "time_test = np.zeros((count_itp, count_itk))\n",
    "for cp in range(count_itp):\n",
    "    N_samples = start_p * (inc_mul_p ** cp)\n",
    "    X, _ = make_blobs(n_samples=N_samples, centers=np.random.randint(low=3, high=8),\n",
    "            cluster_std=0.5 + N_samples/500000, random_state=cp)\n",
    "    for ck in range(count_itk):\n",
    "        start_time = time.time()\n",
    "        _, _ = find_clusters(X, start_k + inc_add_k * ck)\n",
    "        print(\"{}/{}, {}/{}\".format(N_samples, start_p * (inc_mul_p ** (count_itp-1)),\n",
    "                                start_k + inc_add_k * ck, start_k + (count_itk-1)*inc_add_k))\n",
    "        time_test[cp][ck] = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Q9u9p4Tw7zwn",
    "outputId": "4e6e2b61-017b-4ad1-d374-23a5d281951f"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 12))\n",
    "fig.suptitle('On blobs', fontsize=24)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "X = [start_p * (inc_mul_p ** (i)) for i in range(count_itp)]\n",
    "Y = range(start_k, start_k + count_itk*inc_add_k, inc_add_k)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "surf = ax.plot_surface(X, Y, time_test, rstride=8, cstride=8, alpha=0.3)\n",
    "cset = ax.contour(X, Y, time_test, zdir='x', offset=0,cmap=plt.cm.coolwarm)\n",
    "cset = ax.contour(X, Y, time_test, zdir='y', offset=12,cmap=plt.cm.coolwarm)\n",
    "ax.set_xlabel('N_points, шт.')\n",
    "ax.set_ylabel('K, шт.')\n",
    "ax.set_zlabel('Time, с.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 671
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "z6shW8lYs435",
    "outputId": "d9ae2a35-7d5f-48ef-ae26-05007dcd6556"
   },
   "outputs": [],
   "source": [
    "N_samples = 600\n",
    "n_clusters = 6\n",
    "cluster_std = 0.5\n",
    "random_state = 9\n",
    "X, y_true = make_blobs(n_samples=N_samples, centers=n_clusters,\n",
    "                       cluster_std=cluster_std, random_state=random_state)\n",
    "print_find_cl(X, n_clusters)\n",
    "print_sdist_matrix(X, n_clusters=n_clusters, K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "00IntzwdHyT6",
    "outputId": "0667f7cd-d518-4b37-c0b2-1d9cb9856640"
   },
   "outputs": [],
   "source": [
    "N_samples = 300\n",
    "n_clusters = 12\n",
    "random_state = 2\n",
    "X, y_true = make_gaussian_quantiles(n_samples=N_samples, n_classes=n_clusters, random_state=random_state)\n",
    "print_find_cl(X, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "uCTg75WtJRPi",
    "outputId": "16bf978d-0140-4694-8705-221cf28ddbee"
   },
   "outputs": [],
   "source": [
    "print_k_methods(X, eps=30, max_amout_cl=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "dC5yOLlX4LTR",
    "outputId": "a4fa532a-49c2-4af0-bfaf-f7517b5c4adb"
   },
   "outputs": [],
   "source": [
    "X2 = squareform(pdist(X))\n",
    "fig = plt.figure(num=1, figsize=(8, 5))\n",
    "plt.matshow(X2,fignum=1,cmap='Purples_r')\n",
    "plt.colorbar(orientation='vertical', pad=0.06);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "NBduE6gmZUGo",
    "outputId": "3d659773-22c3-4645-fc95-78c32732fac5"
   },
   "outputs": [],
   "source": [
    "print_sdist_matrix(X, n_clusters=12, K=9)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dz1_code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
